{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fee8a4",
   "metadata": {},
   "source": [
    "# **HUD Project — Baseline para Detección de Objetos**\n",
    "\n",
    "Este cuaderno desarrolla un **experimento inicial de detección de objetos** dentro del marco del proyecto HUD (*Heads-Up Display*). El objetivo principal es establecer un **modelo de referencia (baseline)** utilizando **TensorFlow/Keras**, que permita comprender el flujo completo de entrenamiento y validación de una red neuronal convolucional sencilla, antes de avanzar hacia arquitecturas más sofisticadas y específicas para la tarea.\n",
    "\n",
    "El diseño del baseline cumple varias funciones esenciales:\n",
    "\n",
    "* **Verificación del pipeline de datos:** asegurar que la estructura de carpetas, los generadores y la lectura de imágenes funcionan correctamente en TensorFlow.\n",
    "* **Comprensión del ciclo de entrenamiento:** observar cómo evoluciona la pérdida y la exactitud en función de los hiperparámetros iniciales.\n",
    "* **Punto de comparación:** establecer métricas iniciales (loss, accuracy) que servirán de referencia frente a modelos más avanzados (transfer learning, arquitecturas profundas como RetinaNet o EfficientNet).\n",
    "* **Rigor metodológico:** documentar de manera clara los parámetros empleados, la configuración del modelo y los resultados obtenidos, siguiendo buenas prácticas reproducibles.\n",
    "\n",
    "Este cuaderno no busca únicamente entrenar un modelo sencillo, sino también **proporcionar una base de aprendizaje** sobre la que se podrán realizar variaciones controladas de hiperparámetros y arquitecturas, facilitando así un proceso de mejora iterativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d47cdf",
   "metadata": {},
   "source": [
    "## **Estructura del Notebook**\n",
    "\n",
    "1. **Configuración y Parámetros Globales**\n",
    "   Definición de hiperparámetros esenciales (número de clases, batch size, tamaño de entrada, número de épocas, etc.), junto con las rutas de datos.\n",
    "\n",
    "2. **Carga y Exploración de Datos**\n",
    "   Preparación de generadores de entrenamiento y test con `ImageDataGenerator`, conteo de imágenes por clase y visualización de distribuciones.\n",
    "\n",
    "3. **Construcción del Modelo Baseline**\n",
    "   Implementación de una red convolucional sencilla (CNN) con capas `Conv2D`, `MaxPooling2D` y `Dense`.\n",
    "\n",
    "4. **Entrenamiento del Modelo**\n",
    "   Configuración del proceso de entrenamiento, compilación con `Adam`, función de pérdida y registro de métricas.\n",
    "\n",
    "5. **Evaluación y Análisis de Resultados**\n",
    "   Cálculo de accuracy y pérdida en test, representación gráfica de curvas de entrenamiento y discusión de limitaciones.\n",
    "\n",
    "6. **Variantes y Experimentación Inicial**\n",
    "   Exploración de modificaciones básicas: diferentes tamaños de imagen, ajustes de tasa de aprendizaje, cambios de batch size o incorporación de augmentación ligera.\n",
    "\n",
    "7. **Conclusiones y Próximos Pasos**\n",
    "   Reflexión sobre el desempeño del baseline, criterios para considerarlo aceptable y propuesta de mejoras con arquitecturas más robustas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547b0be",
   "metadata": {},
   "source": [
    "## **Configuración y Parámetros Globales**\n",
    "\n",
    "En esta sección se establecen los **parámetros fundamentales del experimento**, así como las rutas a los datos que alimentarán el modelo. La definición explícita de estos elementos resulta esencial para garantizar la **reproducibilidad** de los resultados y proporcionar un **marco de referencia claro** sobre el cual se podrán realizar posteriores variaciones controladas.\n",
    "\n",
    "Los parámetros que se especifican a continuación cumplen diferentes funciones:\n",
    "\n",
    "* **Número de clases (`N_CLASS`)**: determina la dimensionalidad de la capa de salida del modelo y se corresponde con el número total de categorías presentes en el conjunto de datos.\n",
    "* **Tamaño de batch (`BATCH`)**: controla el número de imágenes procesadas simultáneamente durante el entrenamiento, influyendo tanto en la estabilidad de la optimización como en el uso de memoria de la GPU.\n",
    "* **Dimensiones de entrada (`ROWS`, `COLS`, `SHAPE`)**: definen la resolución de las imágenes con las que trabajará la red. Estas dimensiones deben mantenerse consistentes entre los generadores de datos y la capa de entrada del modelo.\n",
    "* **Número de épocas (`EPOCHS`)**: establece la cantidad de veces que el modelo recorrerá el conjunto de entrenamiento completo, permitiendo observar la convergencia del aprendizaje.\n",
    "* **Número máximo de muestras (`TRAIN_SAMPLES`, `TEST_SAMPLES`)**: se incluyen como parámetros opcionales para limitar el número de pasos por época en escenarios de validación rápida o cuando se dispone de recursos computacionales restringidos.\n",
    "\n",
    "Asimismo, se definen las **rutas de los directorios de datos**, que deben seguir la estructura esperada por `ImageDataGenerator` en Keras:\n",
    "\n",
    "* `train_dir`: carpeta raíz que contiene las subcarpetas con las imágenes de entrenamiento organizadas por clase.\n",
    "* `test_dir`: carpeta raíz con la misma organización, utilizada para la fase de validación y prueba.\n",
    "\n",
    "Finalmente, se fijará una **semilla aleatoria global** con el propósito de asegurar que la inicialización de los pesos, el barajado de los datos y otros procesos estocásticos puedan reproducirse de forma exacta en ejecuciones futuras.\n",
    "\n",
    "En conjunto, esta sección constituye la **base experimental del notebook**, y cualquier variación posterior de hiperparámetros deberá documentarse en relación con estos valores iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f149cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identidad del experimento\n",
    "EXPERIMENT_NAME = \"det_cnn_baseline_tf\"\n",
    "DATASET_VERSION = \"roboflow_detect_v1\"\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas base\n",
    "ROOT = Path.cwd()\n",
    "if (ROOT / \"data\").exists():\n",
    "    REPO_ROOT = ROOT\n",
    "elif (ROOT.parent / \"data\").exists():\n",
    "    REPO_ROOT = ROOT.parent\n",
    "else:\n",
    "    REPO_ROOT = ROOT.parent.parent\n",
    "\n",
    "DATA_DIR        = REPO_ROOT / \"data\"\n",
    "DETECT_RAW_DIR  = DATA_DIR / \"detect_raw\"\n",
    "\n",
    "DR_TRAIN_IMAGES = DETECT_RAW_DIR / \"train\" / \"images\"\n",
    "DR_VALID_IMAGES = DETECT_RAW_DIR / \"valid\" / \"images\"\n",
    "DR_TEST_IMAGES  = DETECT_RAW_DIR / \"test\"  / \"images\"\n",
    "\n",
    "DR_TRAIN_LABELS = DETECT_RAW_DIR / \"train\" / \"labels\"\n",
    "DR_VALID_LABELS = DETECT_RAW_DIR / \"valid\" / \"labels\"\n",
    "DR_TEST_LABELS  = DETECT_RAW_DIR / \"test\"  / \"labels\"\n",
    "\n",
    "DR_DATA_YAML    = DETECT_RAW_DIR / \"data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "BATCH = 32\n",
    "ROWS, COLS = 224, 224\n",
    "SHAPE = (ROWS, COLS, 3)\n",
    "EPOCHS = 15\n",
    "TRAIN_SAMPLES = 3000\n",
    "TEST_SAMPLES  = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ceed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DR_DATA_YAML.exists():\n",
    "    raise FileNotFoundError(f\"No se encontró {DR_DATA_YAML}. Verifica tu export de Roboflow.\")\n",
    "\n",
    "with open(DR_DATA_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    rf_cfg = yaml.safe_load(f)\n",
    "\n",
    "RF_CLASSES = rf_cfg.get(\"names\") or rf_cfg.get(\"names:\", [])\n",
    "if isinstance(RF_CLASSES, dict):\n",
    "    RF_CLASSES = [RF_CLASSES[k] for k in sorted(RF_CLASSES.keys(), key=lambda x: int(x))]\n",
    "\n",
    "if not isinstance(RF_CLASSES, (list, tuple)) or len(RF_CLASSES) == 0:\n",
    "    raise ValueError(\"No se pudieron leer las clases desde data.yaml (campo 'names'). Revisa el archivo.\")\n",
    "\n",
    "N_CLASS = len(RF_CLASSES) # Multietiqueta: una salida por clase (sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7fffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] TensorFlow: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"[INFO] GPUs detectadas: {len(gpus)} -> {gpus}\" if gpus else \"[WARN] No se detectó GPU. Entrenamiento más lento.\")\n",
    "\n",
    "def _flag(p: Path) -> str:\n",
    "    return \"OK\" if p.exists() else \"NO\"\n",
    "\n",
    "print(\"\\n[INFO] Estructura Roboflow (detección - RAW):\")\n",
    "print(f\"  {DR_TRAIN_IMAGES}  [{_flag(DR_TRAIN_IMAGES)}]\")\n",
    "print(f\"  {DR_TRAIN_LABELS}  [{_flag(DR_TRAIN_LABELS)}]\")\n",
    "print(f\"  {DR_VALID_IMAGES}  [{_flag(DR_VALID_IMAGES)}]\")\n",
    "print(f\"  {DR_VALID_LABELS}  [{_flag(DR_VALID_LABELS)}]\")\n",
    "print(f\"  {DR_TEST_IMAGES}   [{_flag(DR_TEST_IMAGES)}]\")\n",
    "print(f\"  {DR_TEST_LABELS}   [{_flag(DR_TEST_LABELS)}]\")\n",
    "print(f\"  {DR_DATA_YAML}     [{_flag(DR_DATA_YAML)}]\")\n",
    "\n",
    "print(\"\\n[INFO] Clases detectadas (data.yaml):\")\n",
    "print(f\"  N_CLASS = {N_CLASS}\")\n",
    "print(f\"  CLASSES = {RF_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"dataset_version\": DATASET_VERSION,\n",
    "    \"seed\": SEED,\n",
    "    \"params\": {\n",
    "        \"N_CLASS\": N_CLASS,\n",
    "        \"BATCH\": BATCH,\n",
    "        \"ROWS\": ROWS,\n",
    "        \"COLS\": COLS,\n",
    "        \"SHAPE\": SHAPE,\n",
    "        \"EPOCHS\": EPOCHS,\n",
    "        \"TRAIN_SAMPLES\": TRAIN_SAMPLES,\n",
    "        \"TEST_SAMPLES\": TEST_SAMPLES\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"repo_root\": str(REPO_ROOT),\n",
    "        \"data_dir\": str(DATA_DIR),\n",
    "        \"detect_raw\": str(DETECT_RAW_DIR),\n",
    "        \"dr_train_images\": str(DR_TRAIN_IMAGES),\n",
    "        \"dr_train_labels\": str(DR_TRAIN_LABELS),\n",
    "        \"dr_valid_images\": str(DR_VALID_IMAGES),\n",
    "        \"dr_valid_labels\": str(DR_VALID_LABELS),\n",
    "        \"dr_test_images\":  str(DR_TEST_IMAGES),\n",
    "        \"dr_test_labels\":  str(DR_TEST_LABELS),\n",
    "        \"rf_data_yaml\": str(DR_DATA_YAML)\n",
    "    },\n",
    "    \"rf_classes\": RF_CLASSES\n",
    "}\n",
    "\n",
    "print(\"\\n[INFO] Configuración inicial:\")\n",
    "print(json.dumps(config, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e05cc",
   "metadata": {},
   "source": [
    "## **Carga de datos multietiqueta y preparación de generadores (Keras)**\n",
    "\n",
    "**Idea clave:** una misma imagen puede contener varias clases a la vez. Por eso no usaremos carpetas por clase, sino que construiremos, para cada imagen, un **vector multi-hot** (0/1 por clase) leyendo los **labels YOLO**. Con ese vector alimentaremos generadores de Keras, manteniendo el **reescalado `1./255`** y los **parámetros** previamente definidos.\n",
    "\n",
    "* Convertir los `.txt` de `labels/` (formato YOLO) en una etiqueta **multietiqueta por imagen**: una dimensión por clase (en el orden de `data.yaml`), con 1 si aparece al menos un objeto de esa clase en la imagen y 0 si no.\n",
    "* Mantener intacta la estructura Roboflow (`detect_raw/train|valid|test/{images,labels}`).\n",
    "* Preparar tres generadores Keras (train/valid/test) con `ImageDataGenerator(rescale=1./255)` y `flow_from_dataframe(..., class_mode='raw')`, que aceptan vectores multi-hot sin mover archivos.\n",
    "\n",
    "**Entradas:** Como entradas vamos a necesitar las **imágenes** (`.../train/images`, `.../valid/images`, `.../test/images`); **etiquetas YOLO** (una línea por objeto: `class_id cx cy w h` normalizado) (`.../train/labels`, `.../valid/labels`, `.../test/labels`); **definición de clases y orden**, es decir, del archivo generado por Roboflow `data.yaml` el campo `names` (lista o dict `{id: \"clase\"}`) que fija el **orden** y el **número de clases**.\n",
    "\n",
    "**Salidas:**\n",
    "\n",
    "1. Tres **tablas** (train/valid/test) con:\n",
    "   * `filename` (nombre del fichero de imagen)\n",
    "   * una columna por clase (0/1) en el mismo orden que `names` de `data.yaml`.\n",
    "2. Tres **generadores Keras**:\n",
    "   * `train_gen`, `valid_gen`, `test_gen` usando `flow_from_dataframe`\n",
    "   * `x = filename` (resuelto dentro de la carpeta `images/` de cada split)\n",
    "   * `y = vector multi-hot` (con `class_mode='raw'`)\n",
    "   * `rescale=1./255`, `target_size=(ROWS, COLS)`, `color_mode='rgb'`, `batch_size=BATCH`\n",
    "   * barajado (**shuffle**) solo en `train`.\n",
    "3. **Resumen de control de calidad** por split:\n",
    "\n",
    "   * nº de imágenes\n",
    "   * nº de imágenes con ≥1 clase y sin ninguna\n",
    "   * frecuencia por clase (para detectar desbalance)\n",
    "   * incidencias detectadas (p. ej., labels ausentes).\n",
    "\n",
    "\n",
    "**Recordatorio**\n",
    "\n",
    "* **Resuelve**: saber **qué clases aparecen** en cada imagen (posible multietiqueta).\n",
    "* **No resuelve**: no hay **cajas** ni **coordenadas** (eso lo haremos en la sección de detección real más adelante con un pipeline específico).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame multi-hot desde YOLO\n",
    "VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "\n",
    "def build_multilabel_df(images_dir: Path, labels_dir: Path, class_names):\n",
    "    \"\"\"\n",
    "    Recorre images_dir y crea un DataFrame con:\n",
    "        - filename\n",
    "        - una columna por clase (0/1) indicando presencia en la imagen (según labels YOLO)\n",
    "    Devuelve (df, issues) donde 'issues' resume incidencias detectadas.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    issues = {\n",
    "        \"images_count\": 0,\n",
    "        \"missing_label_files\": 0,\n",
    "        \"invalid_class_ids\": 0,\n",
    "        \"empty_label_files\": 0\n",
    "    }\n",
    "\n",
    "    images = sorted([p for p in images_dir.iterdir() if p.suffix.lower() in VALID_EXTS])\n",
    "    issues[\"images_count\"] = len(images)\n",
    "\n",
    "    for img_path in images:\n",
    "        # Vector multi-hot\n",
    "        y_vec = [0] * len(class_names)\n",
    "        lbl_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "\n",
    "        if lbl_path.exists():\n",
    "            any_label = False\n",
    "            with open(lbl_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:\n",
    "                        continue\n",
    "                    # YOLO: class_id cx cy w h\n",
    "                    try:\n",
    "                        cls_id = int(float(parts[0]))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    if 0 <= cls_id < len(class_names):\n",
    "                        y_vec[cls_id] = 1\n",
    "                        any_label = True\n",
    "                    else:\n",
    "                        issues[\"invalid_class_ids\"] += 1\n",
    "            if not any_label:\n",
    "                issues[\"empty_label_files\"] += 1\n",
    "        else:\n",
    "            # sin .txt -> tratamos como negativo (ninguna clase presente)\n",
    "            issues[\"missing_label_files\"] += 1\n",
    "\n",
    "        row = {\"filename\": img_path.name}\n",
    "        row.update({class_names[i]: y_vec[i] for i in range(len(class_names))})\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Asegurar orden de columnas: filename + clases (en el mismo orden que data.yaml)\n",
    "    df = df[[\"filename\"] + list(class_names)]\n",
    "    return df, issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir DataFrames por split\n",
    "\n",
    "class_cols = RF_CLASSES  # del data.yaml leído en Sección 1\n",
    "\n",
    "df_train, issues_train = build_multilabel_df(DR_TRAIN_IMAGES, DR_TRAIN_LABELS, class_cols)\n",
    "df_valid, issues_valid = build_multilabel_df(DR_VALID_IMAGES, DR_VALID_LABELS, class_cols)\n",
    "df_test,  issues_test  = build_multilabel_df(DR_TEST_IMAGES,  DR_TEST_LABELS,  class_cols)\n",
    "\n",
    "print(\"[INFO] DataFrames creados:\",\n",
    "      f\"train={len(df_train)} | valid={len(df_valid)} | test={len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfeaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Guardar auditoría rápida para revisión\n",
    "AUDIT_DIR = (REPO_ROOT / \"runs_tf\" / \"audits\")\n",
    "AUDIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df_train.to_csv(AUDIT_DIR / \"df_train_multilabel.csv\", index=False)\n",
    "df_valid.to_csv(AUDIT_DIR / \"df_valid_multilabel.csv\", index=False)\n",
    "df_test.to_csv(AUDIT_DIR / \"df_test_multilabel.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resúmenes por split (conteos + barras)\n",
    "def summarize_split(df, issues, split_name):\n",
    "    total = len(df)\n",
    "    if total == 0:\n",
    "        print(f\"\\n=== [{split_name.upper()}] ===\\nSin imágenes.\")\n",
    "        return\n",
    "\n",
    "    any_pos = int((df[class_cols].sum(axis=1) > 0).sum())\n",
    "    none_pos = total - any_pos\n",
    "    per_class = df[class_cols].sum().astype(int)\n",
    "\n",
    "    print(f\"\\n=== [{split_name.upper()}] ===\")\n",
    "    print(f\"Imágenes totales:         {total}\")\n",
    "    print(f\"Con ≥1 clase presente:    {any_pos}\")\n",
    "    print(f\"Sin ninguna clase (neg.): {none_pos}\")\n",
    "    print(\"Presencia por clase:\")\n",
    "    for c, v in per_class.items():\n",
    "        print(f\"  - {c:<20} {v}\")\n",
    "    print(\"Incidencias:\")\n",
    "    for k, v in issues.items():\n",
    "        print(f\"  - {k}: {v}\")\n",
    "\n",
    "    # Gráfico rápido\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        per_class.plot(kind=\"bar\")\n",
    "        plt.title(f\"Presencia por clase — {split_name}\")\n",
    "        plt.ylabel(\"Imágenes con la clase\")\n",
    "        plt.xlabel(\"Clase\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] No se pudo graficar:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_split(df_train, issues_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_split(df_valid, issues_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20623f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_split(df_test,  issues_test,  \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Generadores Keras (multietiqueta, rescale=1./255)\n",
    "datagen_train = ImageDataGenerator(rescale=1./255)\n",
    "datagen_valid = ImageDataGenerator(rescale=1./255)\n",
    "datagen_test  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = datagen_train.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    directory=str(DR_TRAIN_IMAGES),\n",
    "    x_col=\"filename\",\n",
    "    y_col=class_cols,\n",
    "    class_mode=\"raw\",            # Multietiqueta\n",
    "    target_size=(ROWS, COLS),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_gen = datagen_valid.flow_from_dataframe(\n",
    "    dataframe=df_valid,\n",
    "    directory=str(DR_VALID_IMAGES),\n",
    "    x_col=\"filename\",\n",
    "    y_col=class_cols,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(ROWS, COLS),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = datagen_test.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=str(DR_TEST_IMAGES),\n",
    "    x_col=\"filename\",\n",
    "    y_col=class_cols,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(ROWS, COLS),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Evaluate\n",
    "\n",
    "def compute_steps(n_samples, batch_size, max_samples=None):\n",
    "    total = min(n_samples, max_samples) if (max_samples and max_samples > 0) else n_samples\n",
    "    return int(np.ceil(total / float(batch_size))) if total > 0 else 0\n",
    "\n",
    "STEPS_PER_EPOCH = compute_steps(train_gen.n, BATCH, TRAIN_SAMPLES)\n",
    "VAL_STEPS       = compute_steps(valid_gen.n, BATCH, None)         # Usar todo valid\n",
    "TEST_STEPS      = compute_steps(test_gen.n,  BATCH, TEST_SAMPLES)\n",
    "\n",
    "print(\"\\n[INFO] Steps:\")\n",
    "print(f\"  STEPS_PER_EPOCH = {STEPS_PER_EPOCH}\")\n",
    "print(f\"  VAL_STEPS       = {VAL_STEPS}\")\n",
    "print(f\"  TEST_STEPS      = {TEST_STEPS}\")\n",
    "\n",
    "if STEPS_PER_EPOCH == 0:\n",
    "    print(\"[WARN] No hay muestras en train. Revisa rutas/extensiones/clases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b4179",
   "metadata": {},
   "source": [
    "## **Modelo Keras multietiqueta**\n",
    "\n",
    "Entrenar una **CNN sencilla** en TensorFlow/Keras que, dada una imagen completa, prediga **qué clases aparecen** en ella (pueden ser varias a la vez).\n",
    "\n",
    "**Arquitectura**\n",
    "\n",
    "* **Entrada:** `input_shape = SHAPE` (por ej. 224×224×3).\n",
    "* **Bloques convolucionales:** 2–3 repeticiones de `Conv2D(32, 3×3, relu)` seguidas de `MaxPooling2D(2×2)` para reducir resolución y extraer patrones.\n",
    "* **Cabeza densa:** `Flatten()` → `Dense(512, relu)` para combinar características.\n",
    "* **Capa de salida:** `Dense(N_CLASS, activation='sigmoid')`.\n",
    "\n",
    "  * Cambiamos **softmax → sigmoid** porque **pueden activarse varias clases** simultáneamente (no son mutuamente excluyentes).\n",
    "\n",
    "> Nota: Seguimos un diseño **ligero** para iterar rápido.\n",
    "\n",
    "**Compilación (pérdida y métricas)**\n",
    "\n",
    "* **Optimizador:** `Adam(learning_rate=1e-4)`\n",
    "* **Pérdida:** `binary_crossentropy` (una BCE por clase, suma/promedio).\n",
    "* **Métricas:**\n",
    "  * `binary_accuracy` (rápida, pero puede ser optimista si hay muchas ausencias).\n",
    "  * Recomendado añadir métricas por probabilidad: `AUC` multi-etiqueta, y/o precisión/recobrado micro/macro para el informe.\n",
    "* **Reescalado:** ya lo aplican los generadores con `rescale=1./255`\n",
    "\n",
    "**Callbacks (entrenamiento más estable)**\n",
    "\n",
    "* **ModelCheckpoint:** guardar pesos por época o el “mejor” según `val_loss` (carpeta `runs_tf/detect_cnn_multilabel/`).\n",
    "* **EarlyStopping (opcional):** parar si `val_loss` no mejora tras X épocas (útil con `EPOCHS` grandes).\n",
    "* **TensorBoard (opcional):** para visualizar curvas de entrenamiento.\n",
    "\n",
    "\n",
    "**Limitaciones y siguiente paso**\n",
    "\n",
    "* Este modelo **no produce cajas**; solo presencia/ausencia de clases.\n",
    "* Sirve como **baseline didáctico** y para detectar si el dataset/clases están bien formados.\n",
    "* **Próximo paso** en el mismo notebook: sección de **detección real con KerasCV** (mAP y cajas), que sí cumple la necesidad del HUD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar que existen los generadores de la Sección 2\n",
    "assert 'train_gen' in globals() and 'valid_gen' in globals() and 'test_gen' in globals(), \\\n",
    "    \"Faltan los generadores (train_gen/valid_gen/test_gen) de la Sección 2.\"\n",
    "assert 'STEPS_PER_EPOCH' in globals() and 'VAL_STEPS' in globals() and 'TEST_STEPS' in globals(), \\\n",
    "    \"Faltan STEPS_PER_EPOCH / VAL_STEPS / TEST_STEPS (calculados en la Sección 2).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"animal\",\"bicycle\",\"bus\",\"car\",\"direction_sign\",\"mandatory_sign\",\n",
    "    \"motorcycle\",\"obstacle\",\"parking_sign\",\"pedestrian\",\"prohibition_sign\",\n",
    "    \"speed_limit_sign\",\"stop_sign\",\"tractor\",\"traffic_cone\",\"traffic_light\",\n",
    "    \"train\",\"truck\",\"unknown_sign\",\"warning_sign\",\"yield_sign\"\n",
    "]\n",
    "assert N_CLASS == len(class_names), \"N_CLASS debe coincidir con el nº de clases\"\n",
    "\n",
    "# Conteos TRAIN que nos diste\n",
    "_total_train = 3350\n",
    "_pos = np.array([\n",
    "    15, 222, 258, 2428, 746, 248,\n",
    "    162, 70, 200, 726, 179,\n",
    "    557, 57, 6, 110, 1721,\n",
    "    3, 414, 50, 493, 12\n",
    "], dtype=np.float32)\n",
    "_neg = _total_train - _pos\n",
    "\n",
    "# pos_weight = negativos/positivos (clase a clase)\n",
    "pos_weight = (_neg / np.maximum(_pos, 1)).astype(\"float32\")\n",
    "pw = tf.constant(pos_weight, dtype=tf.float32)\n",
    "\n",
    "def weighted_bce(y_true, y_pred):\n",
    "    \"\"\"Binary cross-entropy ponderada por clase (usa pos_weight).\"\"\"\n",
    "    eps = 1e-7\n",
    "    y_pred = tf.clip_by_value(y_pred, eps, 1 - eps)\n",
    "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=logits, pos_weight=pw)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición y compilación del modelo\n",
    "model = Sequential(name=\"cnn_multilabel_baseline\")\n",
    "model.add(Input(shape=SHAPE))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(N_CLASS, activation='sigmoid'))  # Multietiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f00a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=weighted_bce,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\"),\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=N_CLASS)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56494cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks y carpetas de salida\n",
    "\n",
    "RUNS_DIR = REPO_ROOT / \"runs_tf\" / \"detect_cnn_multilabel\"\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_BEST = RUNS_DIR / \"best.keras\"\n",
    "\n",
    "cbs = [\n",
    "    # Guardar el mejor modelo según la métrica de validación\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(CKPT_BEST),\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Si el val_loss no mejora, detener el entrenamiento en 5 épocas y restaura los mejores pesos\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Reducir la tasa de aprendizaje si el val_loss no mejora\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Visualización de curvas y métricas en TensorBoard\n",
    "    TensorBoard(\n",
    "        log_dir=str(RUNS_DIR / \"tb\"),\n",
    "        write_graph=False\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96660fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "if STEPS_PER_EPOCH == 0 or VAL_STEPS == 0:\n",
    "    raise RuntimeError(\"STEPS_PER_EPOCH o VAL_STEPS es 0. Revisa datos y parámetros.\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e24a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar historial\n",
    "with open(RUNS_DIR / \"history.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(history.history, f, indent=2) # Persistimos las curvas para consultarlas sin necesidad de reentrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de entrenamiento (pérdida y accuracy binaria)\n",
    "try:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Curvas de pérdida\")\n",
    "    plt.xlabel(\"Época\"); plt.ylabel(\"Loss\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    if \"binary_accuracy\" in history.history:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(history.history[\"binary_accuracy\"], label=\"train_bin_acc\")\n",
    "        plt.plot(history.history[\"val_binary_accuracy\"], label=\"val_bin_acc\")\n",
    "        plt.title(\"Curvas de binary_accuracy\")\n",
    "        plt.xlabel(\"Época\"); plt.ylabel(\"Binary Acc\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"[WARN] No se pudieron graficar curvas:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación en TEST\n",
    "# Cargar el mejor modelo guardado (por si EarlyStopping no coincide con el checkpoint)\n",
    "best_model = tf.keras.models.load_model(CKPT_BEST)\n",
    "test_metrics = best_model.evaluate(\n",
    "    test_gen,\n",
    "    steps=TEST_STEPS if TEST_STEPS > 0 else None,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\n[TEST] Métricas (orden según model.metrics_names):\")\n",
    "print(list(zip(best_model.metrics_names, test_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción y métricas con umbral\n",
    "\n",
    "# Obtener predicciones probabilísticas\n",
    "pred_probs = best_model.predict(\n",
    "    test_gen,\n",
    "    steps=TEST_STEPS if TEST_STEPS > 0 else None,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Etiquetas reales\n",
    "y_true = test_gen.labels\n",
    "# Alinear tamaño por si usamos TEST_STEPS que no cubre todo el set\n",
    "n_preds = pred_probs.shape[0]\n",
    "y_true = y_true[:n_preds]\n",
    "\n",
    "# Umbral 0.5 (puedes ajustar por clase más adelante)\n",
    "y_pred = (pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de clasificación multi-etiqueta (micro/macro)\n",
    "results_report = {\"note\": \"threshold=0.5\", \"classes\": list(class_cols)}\n",
    "try:\n",
    "    # Micro y macro\n",
    "    p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"micro\", zero_division=0\n",
    "    )\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    # Por clase\n",
    "    p_pc, r_pc, f1_pc, support_pc = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    results_report.update({\n",
    "        \"micro\": {\"precision\": float(p_micro), \"recall\": float(r_micro), \"f1\": float(f1_micro)},\n",
    "        \"macro\": {\"precision\": float(p_macro), \"recall\": float(r_macro), \"f1\": float(f1_macro)},\n",
    "        \"per_class\": [\n",
    "            {\n",
    "                \"class\": class_cols[i],\n",
    "                \"precision\": float(p_pc[i]),\n",
    "                \"recall\": float(r_pc[i]),\n",
    "                \"f1\": float(f1_pc[i]),\n",
    "                \"support\": int(support_pc[i])\n",
    "            } for i in range(len(class_cols))\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    print(\"\\n[TEST] Micro/macro F1 con threshold=0.5\")\n",
    "    print(json.dumps(results_report[\"micro\"], indent=2))\n",
    "    print(json.dumps(results_report[\"macro\"], indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[WARN] sklearn no disponible o error calculando métricas detalladas:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar reporte y configuración mínima para reproducibilidad local\n",
    "artifact = {\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"dataset_version\": DATASET_VERSION,\n",
    "    \"input_shape\": SHAPE,\n",
    "    \"rescale\": \"1./255\",\n",
    "    \"classes\": list(class_cols),\n",
    "    \"threshold\": 0.5,\n",
    "    \"test_metrics_keras\": dict(zip(best_model.metrics_names, [float(x) for x in test_metrics])),\n",
    "    \"test_metrics_report\": results_report\n",
    "}\n",
    "with open(RUNS_DIR / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifact, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n[OK] Guardados artefactos en: {RUNS_DIR}\")\n",
    "print(f\" - Mejor modelo: {CKPT_BEST.name}\")\n",
    "print(\" - history.json, manifest.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
